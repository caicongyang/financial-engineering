# !/usr/bin/python
# -*- coding: UTF-8 -*-

"""
ä½¿ç”¨ aiohttp å®ç°ä¸œæ–¹è´¢å¯Œè¡Œæƒ… SSE å®¢æˆ·ç«¯ï¼Œæ•°æ®å­˜å‚¨åˆ°Redis

Redisæ•°æ®ç»“æ„è®¾è®¡ï¼š

1. å®æ—¶è¡Œæƒ…æ•°æ®ï¼š
    - stock:trends:{stock_code}:latest (Hash)
        {
            'trade_time': 'æ—¶é—´',
            'price': 'å½“å‰ä»·',
            'open': 'å¼€ç›˜ä»·',
            'high': 'æœ€é«˜ä»·',
            'low': 'æœ€ä½ä»·',
            'volume': 'æˆäº¤é‡',
            'amount': 'æˆäº¤é¢',
            'avg_price': 'å‡ä»·'
        }

2. å½“æ—¥åˆ†æ—¶æ•°æ®ï¼š
    - stock:trends:{stock_code}:today:{date} (Sorted Set)
        score: timestamp
        member: JSONå­—ç¬¦ä¸²(åŒ…å«å®Œæ•´è¡Œæƒ…æ•°æ®)

3. æ´»è·ƒè‚¡ç¥¨ç»Ÿè®¡ï¼š
    - stock:trends:active:stocks:{date} (Hash)
        {
            'stock_code': 'æ´»è·ƒæ¬¡æ•°',  # æˆäº¤é‡>5ä¸‡å³è®¡æ•°+1
        }

4. æ¦‚å¿µè‚¡å…ƒæ•°æ®ï¼š
    - meta:stock:concept:{stock_code} (Hash)
        {
            'concept_name': 'æ¦‚å¿µåç§°',
            'stock_name': 'è‚¡ç¥¨åç§°'
        }
    
    - meta:concept:stocks:{concept_name} (Hash)
        {
            'stock_code': 'stock_name',  # è‚¡ï¿½ï¿½ï¿½ä»£ç : è‚¡ç¥¨åç§°
        }
    
    - meta:concepts:all (Set)
        ['æ¦‚å¿µ1', 'æ¦‚å¿µ2', ...]  # æ‰€æœ‰æ¦‚å¿µåç§°é›†åˆ

5. çƒ­ç‚¹æ¿å—ç»Ÿè®¡ï¼š
    - hot:concept:stats:{date} (Sorted Set)
        score: æ´»è·ƒè‚¡ç¥¨æ•°é‡
        member: æ¦‚å¿µåç§°

    - hot:concept:active:stocks:{concept_name}:{date} (Set)
        members: [stock_code1, stock_code2, ...]  # è¯¥æ¦‚å¿µä¸‹å½“å¤©çš„æ´»è·ƒè‚¡ç¥¨é›†åˆ

æ•°æ®è¿‡æœŸç­–ç•¥ï¼š
- åˆ†æ—¶æ•°æ®å’Œæ´»è·ƒè‚¡ç¥¨ç»Ÿè®¡ï¼šæ¬¡æ—¥0ç‚¹è‡ªåŠ¨è¿‡æœŸ
- æ¦‚å¿µè‚¡å…ƒæ•°æ®ï¼šæ°¸ä¹…ä¿å­˜

ä½¿ç”¨ç¤ºä¾‹ï¼š
1. è·å–è‚¡ç¥¨æœ€æ–°è¡Œæƒ…ï¼šHGETALL stock:trends:000001:latest
2. è·å–åˆ†æ—¶æ•°æ®ï¼šZRANGE stock:trends:000001:today:20240318 0 -1
3. æŸ¥è¯¢æ´»è·ƒè‚¡ç¥¨ï¼šHGETALL stock:trends:active:stocks:20240318
4. è·å–è‚¡ç¥¨æ¦‚å¿µï¼šHGETALL meta:stock:concept:000001
5. è·å–æ¦‚å¿µè‚¡ç¥¨ï¼šHGETALL meta:concept:stocks:æ–°èƒ½æº
6. è·å–æ‰€æœ‰æ¦‚å¿µï¼šSMEMBERS meta:concepts:all
"""

import aiohttp
import asyncio
import json
import random
from datetime import datetime, timedelta
import logging
from redis.asyncio import Redis
import time
import pandas as pd
from sqlalchemy import create_engine

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,  # æ”¹ä¸º DEBUG çº§åˆ«
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class StockTrendsSSEClient:
    def __init__(self):
        # æœåŠ¡å™¨åˆ—è¡¨
        self.server_list = [f"{i}.push2.eastmoney.com" for i in range(1, 100)]
        self.current_server_index = 0
        
        # Redisé…ç½®
        self.redis_host = '101.43.6.49'
        self.redis_port = 3373
        self.redis_db = 0
        self.redis_password = '24777365ccyCCY!'
        self.redis: Redis = None
        
        # é€šç”¨å‚æ•°
        self.common_params = {
            'fields1': 'f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f17',
            'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58',
            'mpi': '1000',
            'ut': 'fa5fd1943c7b386f172d6893dbfba10b',
            'ndays': '1',
            'iscr': '0',
            'iscca': '0',
            'wbp2u': '1849325530509956|0|1|0|web'
        }
        
        # æµè§ˆå™¨ User-Agents åˆ—è¡¨
        self.user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15'
        ]
        
        # è¯·æ±‚å¤´
        self.headers = {
            'Accept': 'text/event-stream',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Origin': 'https://quote.eastmoney.com',
            'Referer': 'https://quote.eastmoney.com',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"macOS"',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Pragma': 'no-cache'
        }
        
        # é‡è¿ç›¸å…³é…ç½®
        self.max_retries = 5
        self.retry_delay = 5
        self.heartbeat_interval = 60  # å¢åŠ å¿ƒè·³é—´éš”
        self.last_data_time = None
        
        # MySQLé…ç½®
        self.mysql_config = {
            'host': '101.43.6.49',
            'port': 3333,
            'user': 'root',
            'password': 'root',
            'db': 'stock'
        }
        
        # ä¼ä¸šå¾®ä¿¡æœºå™¨äººé…ç½®
        self.webhook_key = "d981e07d-264c-45b3-949b-fb42f9019751"
        self.webhook_url = f"https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key={self.webhook_key}"
        
        # æ¨é€è®°å½•ï¼ˆé¿å…é‡å¤æ¨é€ï¼‰
        self.pushed_stocks = set()

    async def init_redis(self):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        self.redis = Redis(
            host=self.redis_host,
            port=self.redis_port,
            db=self.redis_db,
            password=self.redis_password,
            decode_responses=True  # è‡ªåŠ¨è§£ç å“åº”
        )
        # æµ‹è¯•è¿æ¥
        await self.redis.ping()

    async def save_trends_data(self, stock_code: str, trends_data: list):
        """ä¿å­˜trendsæ•°æ®åˆ°Redis"""
        try:
            today = datetime.now().strftime('%Y%m%d')
            pipe = self.redis.pipeline()
            
            for trend in trends_data:
                try:
                    fields = trend.split(',')
                    if len(fields) == 8:
                        # ä¿®å¤æ—¶é—´æ ¼å¼è§£æ
                        trade_time = fields[0].split()[-1]  # åªå–æ—¶é—´éƒ¨åˆ† "HH:MM:SS"
                        trade_time = trade_time.replace(':', '')  # è½¬æ¢ä¸º "HHMMSS" æ ¼å¼
                        volume_int = int(fields[5])
                        price = float(fields[1])  # å½“å‰ä»·/æ”¶ç›˜ä»·
                        open_price = float(fields[2])  # å¼€ç›˜ä»·
                        
                        # æ„å»ºæ•°æ®å­—å…¸
                        data = {
                            'trade_time': trade_time,
                            'price': str(price),
                            'open': str(open_price),
                            'high': fields[3],
                            'low': fields[4],
                            'volume': str(volume_int),
                            'amount': fields[6],
                            'avg_price': fields[7]
                        }
                        
                        # 1. æ›´æ–°æœ€æ–°è¡Œæƒ… (ä½¿ç”¨hsetæ›¿ä»£hmset)
                        latest_key = f"stock:trends:{stock_code}:latest"
                        pipe.hset(latest_key, mapping=data)
                        
                        # 2. æ·»åŠ åˆ°å½“å¤©çš„åˆ†æ—¶æ•°æ®
                        today_key = f"stock:trends:{stock_code}:today:{today}"
                        score = int(time.mktime(datetime.strptime(trade_time, '%H%M%S').timetuple()))
                        pipe.zadd(today_key, {json.dumps(data): score})
                        
                        # 3. è®¾ç½®è¿‡æœŸæ—¶é—´
                        tomorrow = (datetime.now().replace(hour=0, minute=0, second=0) + 
                                  timedelta(days=1)).timestamp()
                        pipe.expireat(today_key, int(tomorrow))
                        
                        # 4. æ›´æ–°æ´»è·ƒè‚¡ç¥¨é€»è¾‘
                        # æ¡ä»¶1: æˆäº¤é‡å¤§äº20ä¸‡
                        # æ¡ä»¶2: æ”¶ç›˜ä»·å¤§äºå¼€ç›˜ä»·
                        if volume_int > 200000 and price > open_price:
                            active_stocks_key = f"stock:trends:active:stocks:{today}"
                            current_count = await self.redis.hget(active_stocks_key, stock_code)
                            
                            new_count = 1 if current_count is None else int(current_count) + 1
                            pipe.hset(active_stocks_key, stock_code, new_count)
                            logger.debug(f"Stock {stock_code} active count: {new_count}, volume: {volume_int}, price: {price}, open: {open_price}")
                            
                            await self.update_hot_concepts(stock_code)
                            
                            if new_count >= 3 and stock_code not in self.pushed_stocks:
                                # æ›´æ–°æ¨é€æ¶ˆæ¯å†…å®¹ï¼Œæ·»åŠ æ¶¨è·Œä¿¡æ¯
                                price_change = ((price - open_price) / open_price) * 100
                                await self.push_to_wechat(stock_code, new_count, volume_int, price_change)
                                self.pushed_stocks.add(stock_code)
                            
                            pipe.expireat(active_stocks_key, int(tomorrow))
                
                except ValueError as ve:
                    logger.error(f"Error processing trend data: {ve}, data: {trend}")
                    continue
            
            await pipe.execute()
            
        except Exception as e:
            logger.error(f"Error saving trends data for stock {stock_code}: {e}")

    async def get_active_stocks(self, min_count=2):
        """
        è·å–æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨
        :param min_count: æœ€å°æ´»è·ƒæ¬¡æ•°ï¼Œé»˜è®¤ä¸º2è¡¨ç¤ºè‡³å°‘ä¸¤æ¬¡æˆäº¤äº5ä¸‡
        :return: å­—å…¸ï¼ŒåŒ…å«è‚¡ç¥¨ä»£ç å’Œå…¶æ´»è·ƒæ¬¡æ•°
        """
        try:
            today = datetime.now().strftime('%Y%m%d')
            active_stocks_key = f"stock:trends:active:stocks:{today}"
            
            # è·å–æ‰€æœ‰è‚¡ç¥¨åŠå…¶æ´»è·ƒæ¬¡æ•°
            all_stocks = await self.redis.hgetall(active_stocks_key)
            
            # ç­›é€‰å¹¶è¿”å›æ´»è·ƒæ¬¡æ•°å¤§äºç­‰äºmin_countçš„è‚¡ç¥¨åŠå…¶æ¬¡æ•°
            active_stocks = {
                stock_code: int(count) 
                for stock_code, count in all_stocks.items()
                if int(count) >= min_count
            }
            
            return active_stocks
        except Exception as e:
            logger.error(f"Error getting active stocks: {e}")
            return {}

    async def process_sse_data(self, data):
        """å¤„ç† SSE æ•°æ®"""
        try:
            if isinstance(data, str):
                if data.startswith('data:'):
                    data = data[5:].strip()
                
                try:
                    json_data = json.loads(data)
                    
                    # å¤„ç†å¿ƒè·³å“åº”
                    if json_data.get('data') is None:
                        logger.debug("Received heartbeat")
                        return
                    
                    # å¤„ç†å®é™…æ•°æ®
                    if (isinstance(json_data.get('data'), dict) and 
                        json_data['data'].get('trends')):
                        
                        stock_code = json_data['data'].get('code')
                        trends = json_data['data']['trends']
                        
                        if isinstance(trends, list):
                            logger.debug(f"Processing {len(trends)} trends for stock {stock_code}")
                            await self.save_trends_data(stock_code, trends)
                        else:
                            logger.warning(f"Invalid trends format for stock {stock_code}")
                    
                except json.JSONDecodeError as je:
                    logger.error(f"JSON decode error: {je}")
                    logger.error(f"Raw data: {data[:200]}...")
                    
        except Exception as e:
            logger.error(f"Error processing data: {e}")

    def get_next_server(self):
        """è·ä¸‹ä¸€ä¸ªæœåŠ¡å™¨åœ°å€"""
        server = self.server_list[self.current_server_index]
        self.current_server_index = (self.current_server_index + 1) % len(self.server_list)
        return server

    def get_random_server(self):
        """éšæœºè·å–ä¸€ä¸ªæœåŠ¡å™¨åœ°å€"""
        return random.choice(self.server_list)

    def get_base_url(self):
        """è·å–åŸºç¡€URLï¼ˆè¿™é‡Œä½¿ç”¨éšæœºç­–ç•¥ï¼Œä¹Ÿå¯ä»¥æ”¹ç”¨è½®è¯¢ç­–ç•¥ï¼‰"""
        server = self.get_random_server()  # æˆ–ä½¿ç”¨ self.get_next_server()
        return f"https://{server}/api/qt/stock/trends2/sse"

    def get_secid(self, stock_code):
        """ç”Ÿæˆ secid"""
        if stock_code.startswith(('300', '301','00')):
            return f"0.{stock_code}"
        elif stock_code.startswith(('60', '688')):
            return f"1.{stock_code}"
        else:
            raise ValueError(f"Unsupported stock code format: {stock_code}")

    async def heartbeat_check(self, stock_code):
        """å¿ƒè·³æ£€æµ‹"""
        while True:
            await asyncio.sleep(self.heartbeat_interval)
            if self.last_data_time:
                time_since_last_data = (datetime.now() - self.last_data_time).seconds
                if time_since_last_data > self.heartbeat_interval:
                    logger.warning(f"No data received for {time_since_last_data} seconds for {stock_code}")
                    return True  # éœ€è¦é‡è¿
            else:
                logger.warning(f"No data received yet for {stock_code}")
                return True  # éœ€è¦é‡è¿
        return False

    async def connect_with_retry(self, stock_code):
        """å¸¦é‡è¯•æœºåˆ¶çš„è¿æ¥"""
        while True:
            try:
                await self.connect_sse(stock_code)
            except Exception as e:
                logger.error(f"Connection failed for {stock_code}: {e}")
                await asyncio.sleep(5)
                continue

    async def connect_sse(self, stock_code):
        """è¿æ¥ SSE å¹¶å¤„ç†æ•°æ®æµ"""
        try:
            base_url = self.get_base_url()
            params = self.common_params.copy()
            params['secid'] = self.get_secid(stock_code)
            self.headers['User-Agent'] = random.choice(self.user_agents)
            
            logger.info(f"Connecting to {base_url} for stock {stock_code}")
            
            while True:
                try:
                    timeout = aiohttp.ClientTimeout(total=60, connect=10)
                    async with aiohttp.ClientSession(timeout=timeout) as session:
                        async with session.get(
                            base_url,
                            params=params,
                            headers=self.headers,
                            proxy=None,
                            ssl=False,
                            timeout=3 * 60 * 60
                        ) as response:
                            if response.status != 200:
                                logger.error(f"Non-200 status code: {response.status} for {stock_code}")
                                await asyncio.sleep(5)
                                continue
                            
                            buffer = ""
                            async for chunk in response.content:
                                try:
                                    chunk_text = chunk.decode('utf-8')
                                    buffer += chunk_text
                                    
                                    # å¤„ç†å®Œæ•´çš„æ•°æ®å—
                                    while '\n\n' in buffer:
                                        parts = buffer.split('\n\n', 1)
                                        data_part = parts[0]
                                        buffer = parts[1]
                                        
                                        if data_part.startswith('data:'):
                                            data_part = data_part[5:].strip()
                                        
                                        if data_part and data_part != 'undefined':
                                            try:
                                                json_data = json.loads(data_part)
                                                if json_data.get('data'):
                                                    if isinstance(json_data['data'], dict) and json_data['data'].get('trends'):
                                                        trends = json_data['data']['trends']
                                                        if isinstance(trends, list):
                                                            await self.save_trends_data(stock_code, trends)
                                                        else:
                                                            logger.warning(f"Invalid trends format for {stock_code}")
                                                    elif json_data['data'] is None:
                                                        logger.debug(f"Received heartbeat for {stock_code}")
                                            except json.JSONDecodeError as je:
                                                logger.error(f"JSON decode error: {je}")
                                                logger.error(f"Problematic data: {data_part[:200]}...")
                                    
                                    # å¦‚æœç¼“å†²åŒºå¤ªå¤§ï¼Œæ¸…ç†å®ƒ
                                    if len(buffer) > 1024 * 1024:  # 1MB
                                        logger.warning(f"Buffer too large for {stock_code}, clearing")
                                        buffer = ""
                                        
                                except UnicodeDecodeError as ude:
                                    logger.error(f"Unicode decode error for {stock_code}: {ude}")
                                    buffer = ""
                                    continue
                                
                except aiohttp.ClientPayloadError as cpe:
                    logger.error(f"Payload error for {stock_code}: {cpe}")
                    await asyncio.sleep(5)
                    continue
                except aiohttp.ClientError as e:
                    logger.error(f"Connection error for {stock_code}: {e}")
                    await asyncio.sleep(5)
                    continue
                except asyncio.TimeoutError:
                    logger.error(f"Connection timeout for {stock_code}")
                    await asyncio.sleep(5)
                    continue
                    
        except Exception as e:
            logger.error(f"Unexpected error for {stock_code}: {e}", exc_info=True)
            raise

    async def init_concept_stocks(self):
        """åˆå§‹åŒ–æ¦‚å¿µè‚¡ï¿½ï¿½æ®åˆ°Redis"""
        try:
            engine = create_engine(
                f"mysql+pymysql://{self.mysql_config['user']}:{self.mysql_config['password']}@"
                f"{self.mysql_config['host']}:{self.mysql_config['port']}/{self.mysql_config['db']}"
            )

            df = pd.read_sql("SELECT concept_name, stock_code, stock_name FROM t_concept_stock", engine)
            
            pipe = self.redis.pipeline()
            
            # 1. å­˜å‚¨è‚¡ç¥¨åˆ°æ¦‚å¿µçš„æ˜ å°„
            for _, row in df.iterrows():
                stock_key = f"meta:stock:concept:{row['stock_code']}"
                concept_data = {
                    'concept_name': row['concept_name'],
                    'stock_name': row['stock_name']
                }
                pipe.hset(stock_key, mapping=concept_data)  # ä½¿ç”¨hset with mapping
            
            # 2. å­˜å‚¨æ¦‚å¿µåˆ°è‚¡ç¥¨çš„æ˜ å°„
            for concept_name in df['concept_name'].unique():
                concept_stocks = df[df['concept_name'] == concept_name]
                concept_key = f"meta:concept:stocks:{concept_name}"
                
                concept_stocks_data = dict(zip(
                    concept_stocks['stock_code'],
                    concept_stocks['stock_name']
                ))
                pipe.hset(concept_key, mapping=concept_stocks_data)  # ä½¿ç”¨hset with mapping
            
            # 3. å­˜å‚¨æ‰€æœ‰æ¦‚å¿µåç§°é›†åˆ
            all_concepts_key = "meta:concepts:all"
            pipe.sadd(all_concepts_key, *df['concept_name'].unique())
            
            await pipe.execute()
            logger.debug(f"Successfully loaded {len(df)} concept stock records into Redis")
            
        except Exception as e:
            logger.error(f"Error loading concept stocks: {e}")
            raise

    async def get_stock_concepts(self, stock_code):
        """è·å–è‚¡ç¥¨çš„æ¦‚å¿µä¿¡æ¯"""
        try:
            stock_key = f"meta:stock:concept:{stock_code}"
            concepts = await self.redis.hgetall(stock_key)
            return concepts
        except Exception as e:
            logger.error(f"Error getting concepts for stock {stock_code}: {e}")
            return {}

    async def get_concept_stocks(self, concept_name):
        """è·å–æ¦‚å¿µä¸‹çš„æ‰€æœ‰è‚¡ç¥¨"""
        try:
            concept_key = f"meta:concept:stocks:{concept_name}"
            stocks = await self.redis.hgetall(concept_key)
            return stocks
        except Exception as e:
            logger.error(f"Error getting stocks for concept {concept_name}: {e}")
            return {}

    async def get_all_concepts(self):
        """è·å–æ‰€æœ‰æ¦‚å¿µåç§°"""
        try:
            return await self.redis.smembers("meta:concepts:all")
        except Exception as e:
            logger.error(f"Error getting all concepts: {e}")
            return set()

    async def update_hot_concepts(self, stock_code: str):
        """
        æ›´æ–°çƒ­ç‚¹æ¿å—ç»Ÿè®¡
        æ¯åªè‚¡ç¥¨åœ¨åŒä¸€æ¦‚å¿µä¸­åªç»Ÿè®¡ä¸€æ¬¡ï¼Œä¸ç®¡è§¦å‘å¤šå°‘æ¬¡æ´»è·ƒ
        """
        try:
            today = datetime.now().strftime('%Y%m%d')
            
            # è·å–è‚¡ç¥¨çš„æ‰€æœ‰æ¦‚å¿µ
            concepts = await self.get_stock_concepts(stock_code)
            if not concepts:
                return
            
            pipe = self.redis.pipeline()
            
            # éå†è‚¡ç¥¨çš„æ‰€æœ‰æ¦‚å¿µ
            for concept_name in concepts.get('concept_name', '').split(','):
                if not concept_name:
                    continue
                    
                # æ¦‚å¿µæ´»è·ƒè‚¡ç¥¨é›†åˆçš„key
                concept_active_stocks_key = f"hot:concept:active:stocks:{concept_name}:{today}"
                
                # å°†è‚¡ç¥¨æ·»åŠ åˆ°æ¦‚å¿µçš„æ´»è·ƒè‚¡ç¥¨é›†åˆä¸­
                # SADDå‘½ä»¤ï¼šå¦‚æœè‚¡ç¥¨å·²å­˜åœ¨ï¼Œä¸ä¼šé‡å¤æ·»åŠ 
                pipe.sadd(concept_active_stocks_key, stock_code)
                
                # è®¾ç½®è¿‡æœŸæ—¶é—´
                tomorrow = (datetime.now().replace(hour=0, minute=0, second=0) + 
                          timedelta(days=1)).timestamp()
                pipe.expireat(concept_active_stocks_key, int(tomorrow))
                
                # è·å–è¯¥æ¦‚å¿µä¸‹çš„æ´»è·ƒè‚¡ç¥¨æ•°é‡
                active_count = await self.redis.scard(concept_active_stocks_key)
                
                # æ›´æ–°çƒ­ç‚¹æ¿å—æ’è¡Œ
                hot_concepts_key = f"hot:concept:stats:{today}"
                pipe.zadd(hot_concepts_key, {concept_name: active_count})
                pipe.expireat(hot_concepts_key, int(tomorrow))
            
            await pipe.execute()
            
        except Exception as e:
            logger.error(f"Error updating hot concepts for stock {stock_code}: {e}")

    async def get_hot_concepts(self, limit=10):
        """
        è·å–çƒ­ç‚¹æ¿å—æ’è¡Œ
        :param limit: è¿”å›å‰Nä¸ªçƒ­ç‚¹æ¿å—
        :return: [(concept_name, active_stocks_count), ...]
        """
        try:
            today = datetime.now().strftime('%Y%m%d')
            hot_concepts_key = f"hot:concept:stats:{today}"
            
            # è·å–å¾—åˆ†æœ€é«˜çš„Nä¸ªæ¦‚å¿µ
            results = await self.redis.zrevrange(
                hot_concepts_key, 
                0, 
                limit-1, 
                withscores=True
            )
            
            # è½¬æ¢æ ¼å¼å¹¶è¿”å›
            return [(concept, int(score)) for concept, score in results]
            
        except Exception as e:
            logger.error(f"Error getting hot concepts: {e}")
            return []

    async def get_concept_active_stocks(self, concept_name):
        """
        è·å–æ¦‚å¿µä¸‹çš„æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨
        """
        try:
            today = datetime.now().strftime('%Y%m%d')
            concept_active_stocks_key = f"hot:concept:active:stocks:{concept_name}:{today}"
            
            # è·å–è¯¥æ¦‚å¿µä¸‹æ‰€æœ‰æ´»è·ƒè‚¡ç¥¨
            active_stocks = await self.redis.smembers(concept_active_stocks_key)
            return list(active_stocks)
            
        except Exception as e:
            logger.error(f"Error getting active stocks for concept {concept_name}: {e}")
            return []

    async def push_to_wechat(self, stock_code: str, count: int, volume: int, price_change: float):
        """
        æ¨é€æ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡æœºå™¨äºº
        """
        try:
            # è·å–è‚¡ç¥¨çš„æ¦‚å¿µä¿¡æ¯
            stock_concepts = await self.get_stock_concepts(stock_code)
            stock_name = stock_concepts.get('stock_name', 'æœªçŸ¥')
            concepts = stock_concepts.get('concept_name', 'æ— ')

            # è·å–å½“å‰æ—¶é—´
            current_time = datetime.now().strftime('%H:%M:%S')
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            message = (
                f"ğŸ”¥ é«˜æ´»è·ƒåº¦è‚¡ç¥¨æé†’ \n"
                f"æ—¶é—´: {current_time}\n"
                f"è‚¡ç¥¨: {stock_code} {stock_name}\n"
                f"æ¶¨è·Œå¹…: {price_change:.2f}%\n"
                f"æ´»è·ƒæ¬¡æ•°: {count}\n"
                f"å½“å‰æˆäº¤é‡: {volume}\n"
                f"æ‰€å±æ¦‚å¿µ: {concepts}\n"
                f"------------------------\n"
            )

            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "msgtype": "text",
                "text": {
                    "content": message
                }
            }

            # å‘é€è¯·æ±‚
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.webhook_url,
                    json=data,
                    headers={'Content-Type': 'application/json'}
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('errcode') == 0:
                            logger.debug(f"Successfully pushed message for stock {stock_code}")
                        else:
                            logger.error(f"Failed to push message: {result}")
                    else:
                        logger.error(f"Failed to push message, status code: {response.status}")

        except Exception as e:
            logger.error(f"Error pushing message to WeChat: {e}")

    # æ·»åŠ ä¸€ä¸ªæ–¹æ³•åœ¨æ¯å¤©å¼€å§‹æ—¶é‡ç½®æ¨é€è®°å½•
    async def reset_push_records(self):
        """é‡ç½®æ¨é€è®°å½•"""
        self.pushed_stocks.clear()
        logger.debug("Push records have been reset")

async def main():
    try:
        client = StockTrendsSSEClient()
        
        # åˆå§‹åŒ–Redisè¿æ¥
        await client.init_redis()
        
        # åˆå§‹åŒ–æ¦‚å¿µè‚¡æ•°æ®
        logger.debug("Starting to load concept stocks data...")
        await client.init_concept_stocks()
        logger.debug("Concept stocks data loaded successfully")
        
        # è¯»å–è‚¡ç¥¨ä»£ç åˆ—è¡¨
        with open('input.txt', 'r') as f:
            stock_codes = [line.strip() for line in f 
                         if line.strip() and not line.startswith('#')]
        
        if not stock_codes:
            logger.error("No stock codes found in input.txt")
            return
            
        logger.debug(f"Loaded {len(stock_codes)} stock codes from input.txt")
        
        # å¯åŠ¨è¡Œæƒ…ç›‘æ§ä»»åŠ¡
        tasks = [client.connect_with_retry(code) for code in stock_codes]
        await asyncio.gather(*tasks)
        
    except FileNotFoundError:
        logger.error("input.txt not found in current directory")
    except Exception as e:
        logger.error(f"Error in main: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 